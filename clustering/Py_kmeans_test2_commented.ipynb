{"nbformat_minor": 0, "cells": [{"source": "!pwd", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": false}}, {"source": "!ls -lL /user-home/1002/data", "cell_type": "code", "execution_count": 1, "outputs": [{"output_type": "stream", "name": "stdout", "text": "total 15764126\r\n-rwx------. 1 1002 root  1008814344 Oct 26 15:07 gdelt1gb.csv\r\n-rwx------. 1 1002 root 15133650381 Oct 31 20:08 gdelt-skgm-300-16-8_v2.csv\r\n"}], "metadata": {"collapsed": false}}, {"source": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom datetime import datetime\n\n# Want TensorFlow to not allocate memory for \"all of the GPUs\"\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n\n#points_n = 2000\nclusters_n = 5\niteration_n = 100\n\n#device_name = \"/gpu:2\"\ndevice_name = \"/cpu:0\"\nwith tf.device(device_name):     \n    #scenario 1: with generated points\n    #points = tf.constant(np.random.uniform(0, 10, (points_n, 2)))\n    #centroids = tf.Variable(tf.slice(tf.random_shuffle(points), [0, 0], [clusters_n, -1]))\n\n    #scenario 2: with 500 KB data set    \n    #pd_1 = pd.read_csv('/user-home/1002/data/Finance-50-16-8_v4.csv')\n    #points = tf.constant(pd_1.as_matrix())    \n    \n    #scenario 3: with 500 MB data set    \n    #pd_1 = pd.read_csv('/user-home/1002/data/Finance500mb.csv')\n    \n    #scenario 4: with 1 GB data set\n    #pd_1 = pd.read_csv('/user-home/1002/data/gdelt1gb.csv', header=None, index_col=0)\n    #pd_1 = pd.read_csv('/user-home/1002/data/gdelt1.5gb.csv', header=None, index_col=0)\n\n    # ResourceExhaustedError: OOM when allocating tensor with shape[2922450]\n    #pd_1 = pd.read_csv('/user-home/1002/data/gdelt1.66gb.csv', header=None, index_col=0)\n    \n    #scenario 5: with 15GB data set (CPU only)    \n    pd_1 = pd.read_csv('/user-home/1002/data/gdelt-skgm-300-16-8_v2.csv', header=None, index_col=0)\n          \n    df_1 = pd_1.as_matrix()\n    df_ph = tf.placeholder(tf.float64, shape=pd_1.shape)\n    points = tf.get_variable(\"points\", shape=pd_1.shape, dtype=tf.float64, initializer=tf.zeros_initializer())\n    centroids = tf.get_variable(\"centroids\", shape=[clusters_n, pd_1.shape[1]], dtype=tf.float64, initializer=tf.zeros_initializer())\n\n    points_expanded = tf.expand_dims(points, 0)\n    centroids_expanded = tf.expand_dims(centroids.initialized_value(), 1)\n\n    distances = tf.reduce_sum(tf.square(tf.subtract(points_expanded, centroids_expanded)), 2)\n    assignments = tf.argmin(distances, 0)\n\n    assignments = tf.to_int32(assignments)\n    partitions = tf.dynamic_partition(points, assignments, clusters_n)\n    new_centroids = tf.concat([tf.expand_dims(tf.reduce_mean(partition, 0), 0) for partition in partitions], 0)\n\n    update_centroids = tf.assign(centroids, new_centroids)\n\n    init = tf.global_variables_initializer() \n", "cell_type": "code", "execution_count": 2, "outputs": [], "metadata": {"collapsed": true}}, {"source": "# Want TensorFlow to not allocate \"all of the memory\" for the GPUs visible to it\nfrom keras import backend as K\nconfig = tf.ConfigProto()\nconfig.allow_soft_placement=True\nconfig.gpu_options.allow_growth=True\n\ndef run_kmeans():\n    startTime = datetime.now()    \n    #NUM_THREADS = 88\n    #with tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=NUM_THREADS)) as sess:    \n    #with tf.Session(config = tf.ConfigProto(allow_soft_placement=True)) as sess:\n    with tf.Session(config=config) as sess:  \n\n        sess.run(init)\n        sess.run(points.assign(df_ph), feed_dict={df_ph: df_1})\n        sess.run(centroids.assign(tf.slice(tf.random_shuffle(points), [0, 0], [clusters_n, -1])))\n\n        startTime2 = datetime.now()    \n        for step in xrange(iteration_n):\n            [_, centroid_values, points_values, assignment_values] = sess.run([update_centroids, centroids, points, assignments])\n        print(\"Execution time taken:\", datetime.now() - startTime2)   \n        #print \"centroids\" + \"\\n\", centroid_values\n\n    print(\"Total time taken:\", datetime.now() - startTime)  \n\n    #plt.scatter(points_values[:, 0], points_values[:, 1], c=assignment_values, s=50, alpha=0.5)\n    #plt.plot(centroid_values[:, 0], centroid_values[:, 1], 'kx', markersize=15)\n    #plt.show()", "cell_type": "code", "execution_count": 3, "outputs": [{"output_type": "stream", "name": "stderr", "text": "Using TensorFlow backend.\n"}], "metadata": {"scrolled": true, "collapsed": false}}, {"source": "import multiprocessing\n\n# execute code with extra process so that at the end of the process the memory is released\np = multiprocessing.Process(target=run_kmeans)\np.start()\np.join()", "cell_type": "code", "execution_count": 6, "outputs": [{"output_type": "stream", "name": "stdout", "text": "('Execution time taken:', datetime.timedelta(0, 6193, 136158))\n('Total time taken:', datetime.timedelta(0, 6228, 184188))\n"}], "metadata": {"collapsed": false}}, {"source": "", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python2 with DSX Spark", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.13", "name": "python", "pygments_lexer": "ipython2", "file_extension": ".py", "codemirror_mode": {"version": 2, "name": "ipython"}}}}